{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "datadir = \"../data\"\n",
    "gui_train = \"../ptdb_tug.gui\"\n",
    "gui_test = \"../fda_ue.gui\"\n",
    "windowlength = 32\n",
    "frameshift = 15\n",
    "padding = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_crossing(frame):\n",
    "    \"\"\"\n",
    "    Computes zero crossing rate of frame\n",
    "    \"\"\"\n",
    "    count = len(frame)\n",
    "    countZ = np.sum(np.abs(np.diff(np.sign(frame)))) / 2\n",
    "    return np.float64(countZ) / np.float64(count-1.0)\n",
    "\n",
    "\n",
    "def get_energy(frame):\n",
    "    \"\"\"\n",
    "    Computes signal energy of frame\n",
    "    \"\"\"\n",
    "    return np.sum(frame ** 2) / np.float64(len(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "def get_data(gui):\n",
    "    \n",
    "    wav_files = []\n",
    "    voicing_results = []\n",
    "    sample_rate = 0\n",
    "\n",
    "    with open(gui) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if len(line) == 0:\n",
    "                continue\n",
    "            file_name = os.path.join(datadir, line + \".wav\")\n",
    "            voicing_file = os.path.join(datadir, line + \".f0ref\")\n",
    "            sample_rate, data = wavfile.read(file_name)\n",
    "\n",
    "            nSamples = len(data)\n",
    "\n",
    "            # From miliseconds to samples\n",
    "            ns_windowlength = int(round((windowlength * sample_rate) / 1000))\n",
    "            ns_frameshift = int(round((frameshift * sample_rate) / 1000))\n",
    "            ns_padding = int(round((padding * sample_rate) / 1000))\n",
    "\n",
    "            frames = []\n",
    "            for ini in range(-ns_padding, nSamples - ns_windowlength + ns_padding + 1, ns_frameshift):\n",
    "                first_sample = max(0, ini)\n",
    "                last_sample = min(nSamples, ini + ns_windowlength)\n",
    "                frame = data[first_sample:last_sample]\n",
    "                frames.append(frame)\n",
    "\n",
    "            wav_files += frames\n",
    "\n",
    "            with open(voicing_file) as v:\n",
    "                for line in v:\n",
    "                    if line == \"0\":\n",
    "                        voicing_results.append(False)\n",
    "                    else:\n",
    "                        voicing_results.append(True)\n",
    "\n",
    "    np_wav = np.array(wav_files)\n",
    "    np_voicing = np.array(voicing_results)\n",
    "    print(\"nb_samples_wav\", np_wav.size)\n",
    "    print(\"nb_samples_voicing\", np_voicing.size)\n",
    "    print(\"sample_rate\", sample_rate)\n",
    "    np_wav = np_wav[:len(np_voicing)]\n",
    "    \n",
    "    formated_data = []\n",
    "    for data in np_wav:\n",
    "        zc = get_zero_crossing(data)\n",
    "        energy = get_energy(data)\n",
    "        formated_data.append([zc, energy])\n",
    "    np_formated = np.array(formated_data)\n",
    "    np_formated[:5]\n",
    "    \n",
    "    return formated_data, np_voicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_samples_wav 22175\n",
      "nb_samples_voicing 22140\n",
      "sample_rate 20000\n",
      "nb_samples_wav 2308001\n",
      "nb_samples_voicing 3429011\n",
      "sample_rate 48000\n"
     ]
    }
   ],
   "source": [
    "formated_data_test, np_voicing_test = get_data(gui_test)\n",
    "formated_data_train, np_voicing_train = get_data(gui_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_train = np_formated[:len(np_voicing) - len(np_voicing)//10]\n",
    "voicing_train = np_voicing[:len(np_voicing) - len(np_voicing)//10]\n",
    "\n",
    "formated_test = np_formated[len(np_voicing) - len(np_voicing)//10: len(np_voicing)]\n",
    "voicing_test = np_voicing[len(np_voicing) - len(np_voicing)//10: len(np_voicing)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(formated_train, voicing_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = forest_clf.predict(formated_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "number_failures = 0\n",
    "for i in range(len(formated_test)):\n",
    "    if res[i] != voicing_test[i]:\n",
    "        number_failures += 1\n",
    "print(number_failures/len(formated_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
